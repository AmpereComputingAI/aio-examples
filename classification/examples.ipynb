{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Examples\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "    <img src=\"../utils/1ampere_logo_Â®_primary_stacked_rgb.png\" width=\"50%\"/>    \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Ampere AI software stack is the software acceleration layer of Ampere Cloud Native Processors specifically dedicated to accelerating AI workloads running on Ampere Processors. Ampere Optimized AI Frameworks include PyTorch, TensorFlow, and ONNXRuntime. This drop-in library seamlessly supports all AI applications developed in the most popular AI frameworks. It works  right out-of-the-box without API changes or any additional coding. Additionally, the Ampere AI software engineering team provides the publicly accessbile Ampere Model Library (AML) for testing and benchmarking the performance ofAmpere Cloud Native Processors for some of the most common AI inference workloads.\n",
    "\n",
    "Please visit us at https://amperecomputing.com\n",
    "\n",
    "## ImageNet Dataset Overview\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "    <img src=\"https://www.image-net.org/static_files/index_files/logo.jpg\" alt=\"Image not found\" style=\"width: 200px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "These examples are using subset of ImageNet classification validation set from year 2012.\n",
    "ImageNet is a large-scale classification dataset that has been instrumental in advancing computer vision and deep learning research.\n",
    "\n",
    "More info can be found here: https://image-net.org/\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.imagenet import ImageNet\n",
    "import utils.post_processing as pp\n",
    "import utils.benchmark as bench_utils\n",
    "\n",
    "LAT_BATCH_SIZE = 1              # Evaluate latency\n",
    "THROUGHPUT_BATCH_SIZE = 32      # Evaluate throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency with ResNet-50 v1.5 in fp32 precision\n",
    "\n",
    "AIO offers a significant speed-up in standard fp32 inference scenarios. AIO exposes\n",
    "AIO API to control behavior of the optimizer.\n",
    "This example shows the performance of ResNet-50 v1.5 model in fp32 precision.\n",
    "Original ResNet paper can be found here: https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (224, 224)\n",
    "fp32_model = \"resnet_50_v1.5/resnet_50_v1.5_fp32.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize onnx session options \n",
    "session_options = ort.SessionOptions()\n",
    "session_options.intra_op_num_threads = bench_utils.get_intra_op_parallelism_threads()\n",
    "session_options.inter_op_num_threads = 1\n",
    "session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialization of ImageNet dataset\n",
    "imagenet = ImageNet(\n",
    "    batch_size=LAT_BATCH_SIZE,\n",
    "    color_model=\"RGB\",\n",
    "    pre_processing=\"VGG\",\n",
    "    is1001classes=True,\n",
    "    convert_to_fp16=False\n",
    ")\n",
    "\n",
    "input_array = imagenet.get_input_array(target_shape=input_shape)\n",
    "\n",
    "input_dict = dict()\n",
    "input_dict[\"input_tensor:0\"] = input_array\n",
    "\n",
    "output_names = [\"softmax_tensor:0\"]\n",
    "\n",
    "# for the purpose of visualizing results let's load the image without pre-processing\n",
    "img = cv2.imread(str(imagenet.path_to_latest_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# running the model with AIO enabled in fp32 precision\n",
    "\n",
    "ort.AIO.force_enable()\n",
    "\n",
    "sess = ort.InferenceSession(fp32_model, sess_options=session_options, providers=ort.get_available_providers())\n",
    "\n",
    "# warm-up run\n",
    "_ = sess.run(output_names, input_dict)\n",
    "\n",
    "# actual run\n",
    "start = time.time()\n",
    "output_aio = sess.run(output_names, input_dict)\n",
    "finish = time.time()\n",
    "\n",
    "latency_ms = (finish - start) * 1000\n",
    "print(\"\\nResNet-50 v1.5 FP32 latency with AIO: {:.0f} ms\\n\".format(latency_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# running the model with AIO disabled in fp32 precision\n",
    "ort.AIO.force_disable()\n",
    "\n",
    "sess = ort.InferenceSession(fp32_model, sess_options=session_options, providers=ort.get_available_providers())\n",
    "\n",
    "# warm-up run\n",
    "_ = sess.run(output_names, input_dict)\n",
    "\n",
    "# actual run\n",
    "start = time.time()\n",
    "output_no_aio = sess.run(output_names, input_dict)\n",
    "finish = time.time()\n",
    "\n",
    "latency_ms = (finish - start) * 1000\n",
    "print(\"\\nResNet-50 v1.5 FP32 latency without AIO: {:.0f} ms\\n\".format(latency_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# visualizing output\n",
    "\n",
    "# show the image\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print(\"ResNet-50 v1.5 FP32 predictions with AIO enabled:\\n\")\n",
    "print(f\"Top-1 prediction: {pp.get_imagenet_names(imagenet.extract_top1(output_aio[0][0]) + 1)}\")\n",
    "print(f\"Top-5 predictions: {pp.get_imagenet_names(imagenet.extract_top5(output_aio[0][0]) + 1)}\")\n",
    "\n",
    "print(\"\\nResNet-50 v1.5 FP32 predictions with AIO disabled:\\n\")\n",
    "print(f\"Top-1 prediction: {pp.get_imagenet_names(imagenet.extract_top1(output_no_aio[0][0]) + 1)}\")\n",
    "print(f\"Top-5 predictions: {pp.get_imagenet_names(imagenet.extract_top5(output_no_aio[0][0]) + 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput (BS=32) with ResNet-50 v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# let's fill array of shape [32, 3, 224, 224] with our image\n",
    "\n",
    "input_array_bs32 = np.empty([THROUGHPUT_BATCH_SIZE, 3, *input_shape])  # NCHW order\n",
    "for i in range(THROUGHPUT_BATCH_SIZE):\n",
    "    input_array_bs32[i] = input_array\n",
    "    \n",
    "input_array_bs32 = input_array_bs32.astype('float32')\n",
    "input_dict[\"input_tensor:0\"] = input_array_bs32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# running the model with AIO disabled in fp32 precision\n",
    "ort.AIO.force_disable()\n",
    "\n",
    "sess = ort.InferenceSession(fp32_model, sess_options=session_options, providers=ort.get_available_providers())\n",
    "\n",
    "# warm-up run\n",
    "_ = sess.run(output_names, input_dict)\n",
    "\n",
    "# actual run\n",
    "start = time.time()\n",
    "_ = sess.run(output_names, input_dict)\n",
    "finish = time.time()\n",
    "\n",
    "throughput_no_aio = THROUGHPUT_BATCH_SIZE / (finish - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model with AIO enabled in fp32 precision\n",
    "ort.AIO.force_enable()\n",
    "\n",
    "sess = ort.InferenceSession(fp32_model, sess_options=session_options, providers=ort.get_available_providers())\n",
    "\n",
    "# warm-up run\n",
    "_ = sess.run(output_names, input_dict)\n",
    "\n",
    "# actual run\n",
    "start = time.time()\n",
    "_ = sess.run(output_names, input_dict)\n",
    "finish = time.time()\n",
    "\n",
    "throughput_aio = THROUGHPUT_BATCH_SIZE / (finish - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ResNet-50 v1.5 FP32 throughput without AIO: {:.0f} fps\".format(throughput_no_aio))\n",
    "print(\"ResNet-50 v1.5 FP32 throughput with AIO: {:.0f} fps\".format(throughput_aio))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
