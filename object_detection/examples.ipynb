{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Examples\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Ampere AI software stack is the software acceleration layer of Ampere Cloud Native Processors specifically dedicated to accelerating AI workloads running on Ampere Processors. Ampere Optimized AI Frameworks include PyTorch, TensorFlow, and ONNXRuntime. This drop-in library seamlessly supports all AI applications developed in the most popular AI frameworks. It works  right out-of-the-box without API changes or any additional coding. Additionally, the Ampere AI software engineering team provides the publicly accessbile Ampere Model Library (AML) for testing and benchmarking the performance of Ampere Cloud Native Processors for some of the most common AI inference workloads.\n",
    "\n",
    "&nbsp;&nbsp;Please visit us at https://amperecomputing.com\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "## COCO Dataset Overview\n",
    "<img align=\"left\" src=\"https://cocodataset.org/images/coco-logo.png\" alt=\"nn\" style=\"width: 200px;\"/>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "These examples are using subset of COCO object detection validation set from year 2014.\n",
    "COCO is a large-scale object detection, segmentation, and captioning dataset.\n",
    "\n",
    "More info can be found here: https://cocodataset.org\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.coco import COCODataset\n",
    "import utils.post_processing as pp\n",
    "import utils.benchmark as bench_utils\n",
    "\n",
    "LAT_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSD MobileNet v1 \n",
    "\n",
    "This example shows the performance of SSD MobileNet v1 \n",
    "You can read more on SSD MobileNet architecture here: https://arxiv.org/pdf/1801.04381.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (640, 640)\n",
    "threshold = 0.3\n",
    "model = \"ssd_mobilenet_v1/torch2onnx_ssd_mobilenet_v1.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize onnx session options \n",
    "session_options = ort.SessionOptions()\n",
    "session_options.intra_op_num_threads = bench_utils.get_intra_op_parallelism_threads()\n",
    "session_options.inter_op_num_threads = 1\n",
    "session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "session_options.log_severity_level = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialization of COCO dataset\n",
    "coco = COCODataset(\n",
    "    batch_size=LAT_BATCH_SIZE,\n",
    "    color_model=\"BGR\",\n",
    "    images_filename_base=\"COCO_val2014_000000000000\",\n",
    "    pre_processing=False,\n",
    "    sort_ascending=True,\n",
    "    transpose_input=False\n",
    ")\n",
    "\n",
    "input_array = coco.get_input_array(target_shape=input_shape)\n",
    "\n",
    "input_dict = dict()\n",
    "input_dict[\"image_tensor:0\"] = input_array\n",
    "\n",
    "output_names = [\"detection_classes:0\", \"detection_boxes:0\", \"detection_scores:0\", \"num_detections:0\"]\n",
    "\n",
    "# for the purpose of visualizing results let's load the image without pre-processing\n",
    "img = cv2.imread(str(coco.path_to_latest_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# running the model with AIO enabled\n",
    "ort.AIO.force_enable()\n",
    "\n",
    "sess = ort.InferenceSession(model, sess_options=session_options, providers=ort.get_available_providers())\n",
    "\n",
    "# warm-up run\n",
    "_ = sess.run(output_names, input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual run\n",
    "start = time.time()\n",
    "output_aio = sess.run(output_names, input_dict)\n",
    "finish = time.time()\n",
    "\n",
    "latency_ms = (finish - start) * 1000\n",
    "print(\"\\nSSD MobileNet v1 latency with AIO: {:.0f} ms\\n\".format(latency_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# visualizing output\n",
    "\n",
    "# post-processing\n",
    "def post_process(image, det_boxes, det_classes, det_scores, num_det):\n",
    "\n",
    "\n",
    "    for i in range(LAT_BATCH_SIZE):\n",
    "        for d in range(int(num_det)):\n",
    "\n",
    "            # the detected object does not exceed a set threshold we skip it\n",
    "            if det_scores[i][d] < threshold:\n",
    "                continue\n",
    "\n",
    "            # first let's switch order of bbox boundaries from [top left bottom right] to [left top right bottom]\n",
    "            converted_bbox = coco.convert_bbox_to_coco_order(\n",
    "                det_boxes[i][d] * input_shape[0],\n",
    "                1, 0, 3, 2,\n",
    "                absolute=False\n",
    "            )\n",
    "\n",
    "            # then rescale back to original image ratio\n",
    "            converted_bbox = coco.rescale_bbox(i, converted_bbox)\n",
    "\n",
    "            # we can now draw bbox on the original input image\n",
    "            image = pp.draw_bbox(image, converted_bbox, int(det_classes[i][d]))\n",
    "\n",
    "    return image\n",
    "\n",
    "detection_boxes = output_aio[1]\n",
    "detection_classes = output_aio[0]\n",
    "detection_classes += 1  # model uses indexing from 0 while COCO dateset start with idx of 1\n",
    "detection_scores = output_aio[2]\n",
    "num_detections = output_aio[3]\n",
    "\n",
    "# show the post-processed images\n",
    "plt.imshow(cv2.cvtColor(\n",
    "    post_process(img, detection_boxes, detection_classes, detection_scores, num_detections),\n",
    "    cv2.COLOR_BGR2RGB\n",
    "))\n",
    "plt.show()\n",
    "print(\"SSD MobileNet v1 output with AIO enabled\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
