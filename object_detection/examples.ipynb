{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection Examples\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "    <img src=\"../utils/1ampere_logo_Â®_primary_stacked_rgb.png\" alt=\"Image not found\" width=\"50%\"/>    \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Ampere AI software stack is the software acceleration layer of Ampere Cloud Native Processors specifically dedicated to accelerating AI workloads running on Ampere Processors. Ampere Optimized AI Frameworks include PyTorch, TensorFlow, and ONNXRuntime. This drop-in library seamlessly supports all AI applications developed in the most popular AI frameworks. It works  right out-of-the-box without API changes or any additional coding. Additionally, the Ampere AI software engineering team provides the publicly accessbile Ampere Model Library (AML) for testing and benchmarking the performance of Ampere Cloud Native Processors for some of the most common AI inference workloads.\n",
    "\n",
    "Please visit us at https://amperecomputing.com\n",
    "\n",
    "\n",
    "## COCO Dataset Overview\n",
    "<div style=\"text-align: left;\">\n",
    "    <img src=\"https://cocodataset.org/images/coco-logo.png\" alt=\"nn\" style=\"width: 200px;\"/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "These examples are using subset of COCO object detection validation set from year 2014.\n",
    "COCO is a large-scale object detection dataset that has been instrumental in advancing computer vision and deep learning research.\n",
    "\n",
    "More info can be found here: https://cocodataset.org/\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcel/dev/aio-examples/myenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/marcel/dev/aio-examples/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#DELETE BELOW\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.cv.coco import COCODataset\n",
    "import utils.benchmark as bench_utils\n",
    "import utils.misc as utils\n",
    "import utils.post_processing as pp\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "LAT_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency with SSD VGG16 in fp32 precision\n",
    "\n",
    "AIO offers a significant speed-up in standard fp32 inference scenarios. AIO exposes API to control behavior of the optimizer. This example shows the performance of SSD VGG16 model in fp32 precision.\n",
    "Original ResNet paper can be found here: https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIO_NUM_THREADS not defined\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIO_NUM_THREADS = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(num_threads))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Set Pytorch intra thread count, which should match AIO_NUM_THREADS\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_num_threads(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Load model and apply Torchscript for inference deployment\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mdetection\u001b[38;5;241m.\u001b[39mssd300_vgg16(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "# ! AIO_NUM_THREADS should be set prior to launching jupyter notebook !\n",
    "num_threads = os.getenv('AIO_NUM_THREADS')\n",
    "images_path = os.getenv('COCO_IMG_PATH')\n",
    "anno_path = os.getenv('COCO_ANNO_PATH')\n",
    "\n",
    "if num_threads is None:\n",
    "    print(\"AIO_NUM_THREADS not defined\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"AIO_NUM_THREADS = {}\".format(num_threads))\n",
    "\n",
    "# Set Pytorch intra thread count, which should match AIO_NUM_THREADS\n",
    "torch.set_num_threads(int(num_threads))\n",
    "\n",
    "# Load model and apply Torchscript for inference deployment\n",
    "model = torchvision.models.detection.ssd300_vgg16(pretrained=True)\n",
    "model.eval()\n",
    "model_script = torch.jit.script(model)\n",
    "frozen_script = torch.jit.freeze(model_script)\n",
    "\n",
    "# ImageNet dataset initialization\n",
    "input_shape = (300, 300)\n",
    "dataset_aio = COCODataset(LAT_BATCH_SIZE, \"BGR\", \"COCO_val2014_000000000000\", images_path, anno_path,\n",
    "                          pre_processing=\"PyTorch_objdet\", sort_ascending=True, order=\"NCHW\")\n",
    "dataset_non_aio = COCODataset(LAT_BATCH_SIZE, \"BGR\", \"COCO_val2014_000000000000\", images_path, anno_path,\n",
    "                          pre_processing=\"PyTorch_objdet\", sort_ascending=True, order=\"NCHW\")\n",
    "\n",
    "\n",
    "input_array = dataset_aio.get_input_array(input_shape)\n",
    "num_of_runs = dataset_aio.available_instances\n",
    "if num_of_runs <= 2:\n",
    "    print(\"The first two runs are warm up. Please provide more than two input images\")\n",
    "    exit()\n",
    "\n",
    "torch._C._aio_force_enable()\n",
    "count = 0\n",
    "total_time = 0\n",
    "for _ in range(num_of_runs):\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        output_tensor = frozen_script(input_array)\n",
    "        end = time.time()\n",
    "        output_aio = output_tensor[1]\n",
    "        for i in range(LAT_BATCH_SIZE):\n",
    "            for d in range(output_aio[i]['boxes'].shape[0]):\n",
    "                dataset_aio.submit_bbox_prediction(\n",
    "                    i,\n",
    "                    dataset_aio.convert_bbox_to_coco_order(output_aio[i]['boxes'][d].tolist()),\n",
    "                    output_aio[i]['scores'][d].item(),\n",
    "                    output_aio[i]['labels'][d].item()\n",
    "                )\n",
    "        count = count + 1\n",
    "        if count > 2:\n",
    "            total_time += end - start\n",
    "latency_aio = total_time / (count - 2) \n",
    "\n",
    "torch._C._aio_force_disable()\n",
    "input_array = dataset_non_aio.get_input_array(input_shape)\n",
    "num_of_runs = dataset_non_aio.available_instances\n",
    "count = 0\n",
    "total_time = 0\n",
    "for _ in range(num_of_runs):\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        output_tensor = frozen_script(input_array)\n",
    "        end = time.time()\n",
    "        output_non_aio = output_tensor[1]\n",
    "        for i in range(LAT_BATCH_SIZE):\n",
    "            for d in range(output_non_aio[i]['boxes'].shape[0]):\n",
    "                dataset_non_aio.submit_bbox_prediction(\n",
    "                    i,\n",
    "                    dataset_non_aio.convert_bbox_to_coco_order(output_non_aio[i]['boxes'][d].tolist()),\n",
    "                    output_non_aio[i]['scores'][d].item(),\n",
    "                    output_non_aio[i]['labels'][d].item()\n",
    "                )\n",
    "        count = count + 1\n",
    "        if count > 2:\n",
    "            total_time += end - start\n",
    "latency_non_aio = total_time / (count - 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# visualizing output\n",
    "# for the purpose of visualizing results let's load the image without pre-processing\n",
    "img = cv2.imread(str(dataset_aio.path_to_latest_image))\n",
    "\n",
    "def post_process(image, output):\n",
    "    for i in range(LAT_BATCH_SIZE):\n",
    "                for d in range(output_aio[i]['boxes'].shape[0]):\n",
    "                    \n",
    "                    if output_aio[i][\"scores\"][d] < 0.3:\n",
    "                        continue\n",
    "                        \n",
    "                    converted_bbox = dataset_aio.convert_bbox_to_coco_order(\n",
    "                        output_aio[i]['boxes'][d].tolist(),\n",
    "                        absolute=False\n",
    "                    )\n",
    "                \n",
    "                    converted_bbox = dataset_aio.rescale_bbox(i, converted_bbox)\n",
    "                \n",
    "                    image = pp.draw_bbox(img, converted_bbox, int(output_aio[i][\"labels\"][d].tolist()))\n",
    "\n",
    "    return image\n",
    "    \n",
    "# show the image\n",
    "image = cv2.cvtColor(post_process(img, output_aio), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(\"SSD VGG16 FP32 output with AIO enabled\\n\")\n",
    "print(\"Latency = {:.0f} ms\".format(latency_aio * 1000))\n",
    "dataset_aio.summarize_accuracy()\n",
    "\n",
    "image = cv2.cvtColor(post_process(img, output_non_aio), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(\"SSD VGG16 FP32 output with AIO disabled\\n\")\n",
    "print(\"Latency = {:.0f} ms\".format(latency_non_aio * 1000))\n",
    "dataset_non_aio.summarize_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
